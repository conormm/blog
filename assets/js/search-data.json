{
  
    
        "post0": {
            "title": "Lesser known data science techniques you should add to your toolkit (code)",
            "content": "from sklearn.base import BaseEstimator, RegressorMixin from sklearn.base import ClassifierMixin import statsmodels.api as sm import matplotlib.pyplot as plt import seaborn as sns import pandas as pd import numpy as np sns.set_style(&quot;whitegrid&quot;) get_ipython().run_line_magic(&#39;matplotlib&#39;, &#39;inline&#39;) from IPython.core.display import display, HTML display(HTML(&quot;&lt;style&gt;.container { width:80% !important; }&lt;/style&gt;&quot;)) . n = 100 X = np.linspace(0, 30, n) y = 150 + 0.3*X + 1*X**2 + np.random.normal(loc=50, scale=100, size=n) X = X[:, np.newaxis] plt.figure(figsize=(17, 7)) plt.scatter(X, y, alpha=.7); . class QuantileRegression(BaseEstimator, RegressorMixin): &quot;&quot;&quot;Sklearn wrapper for statsmodels Quantile Regression &quot;&quot;&quot; def __init__(self, quantile=0.5, **kwargs): self.quantile = quantile self.kwargs = kwargs self.model = None self.fitted = None def fit(self, X, y=None): X = sm.add_constant(X) self.model = sm.QuantReg(endog=y, exog=X, **self.kwargs) self.fitted = self.model.fit(q=self.quantile) def predict(self, X, y=None): X = sm.add_constant(X) return self.fitted.predict(X) . n = 100 X = np.linspace(0, 30, n) y = 150 + 0.3*X + 1*X**2 + np.random.normal(loc=50, scale=100, size=n) X = X[:, np.newaxis] plt.figure(figsize=(17, 7)) plt.scatter(X, y, alpha=.7); # instantiate models qr_05 = QuantileRegression(.05) qr_50 = QuantileRegression(quantile=.5) qr_95 = QuantileRegression(quantile=.95) # structure data for model model_input = np.c_[X, X**2] # fit models qr_05.fit(model_input, y) qr_50.fit(model_input, y) qr_95.fit(model_input, y) . qr.fitted.summary() . QuantReg Regression Results Dep. Variable: y | Pseudo R-squared: 0.6992 | . Model: QuantReg | Bandwidth: 104.1 | . Method: Least Squares | Sparsity: 268.4 | . Date: Sat, 10 Apr 2021 | No. Observations: 100 | . Time: 17:29:23 | Df Residuals: 97 | . | Df Model: 2 | . | coef std err t P&gt;|t| [0.025 0.975] . const 185.1674 | 39.463 | 4.692 | 0.000 | 106.844 | 263.491 | . x1 8.3116 | 6.080 | 1.367 | 0.175 | -3.755 | 20.378 | . x2 0.7510 | 0.196 | 3.830 | 0.000 | 0.362 | 1.140 | . The condition number is large, 1.2e+03. This might indicate that there arestrong multicollinearity or other numerical problems. plt.figure(figsize=(25, 13)) plt.scatter(X, y) preds_05 = qr_05.predict(model_input) preds_50 = qr_50.predict(model_input) preds_95 = qr_95.predict(model_input) plt.plot(X, preds_05, color=&quot;orange&quot;, label=&quot;0.05 Quantile&quot;) plt.plot(X, preds_50, color=&quot;red&quot;, label=&quot;0.5 Quantile&quot;) plt.plot(X, preds_95, color=&quot;green&quot;, label=&quot;0.95 Quantile&quot;) plt.fill_between(X.reshape(-1,), preds_05.reshape(-1, ), preds_95.reshape(-1, ), color=&quot;blue&quot;, alpha=.3) fs = 30 plt.legend(fontsize=fs/2) plt.title(&quot;Quantile Regression Predictions&quot;, fontsize=fs) plt.xlabel(&quot;X&quot;, fontsize=fs) plt.ylabel(&quot;y&quot;, fontsize=fs) plt.yticks(fontsize=fs) plt.xticks(fontsize=fs); . medium_post_views = np.array([3500, 1600, 482, 245, 198, 116]) days_since_launch = np.arange(medium_post_views.shape[0]) . plt.figure(figsize=(25, 13)) plt.plot(medium_post_views) plt.scatter(days_since_launch, medium_post_views) plt.title(&quot;Medium views decay&quot;, fontsize=fs) plt.ylabel(&quot;Views&quot;, fontsize=fs) plt.yticks(fontsize=fs) plt.xlabel(&quot;Days since launch&quot;, fontsize=fs) plt.xticks(fontsize=fs); . from scipy.optimize import curve_fit from sklearn.base import BaseEstimator, RegressorMixin import statsmodels.api as sm class ExponentialDecayRegressor(BaseEstimator, RegressorMixin): &quot;&quot;&quot;Fits an exponential decay curve &quot;&quot;&quot; def __init__(self, starting_values=[1.,1.e-5,1.], **kwargs,): self.starting_values = starting_values self.kwargs = kwargs self.params = None def fit(self, X, y=None): self.params, _ = curve_fit(self.exp_decay_f, X, y, p0=self.starting_values) def predict(self, X, y=None): return self.exp_decay_f(X, *self.params) @staticmethod def exp_decay_f(X, a, k, b): return a * np.exp(-k*X) + b . medium_post_views = np.array([3500, 1600, 482, 245, 198, 116]) days_since_launch = np.arange(medium_post_views.shape[0]) xd = ExponentialDecayRegressor() xd.fit(days_since_launch, medium_post_views) days_since_launch_plus_future = np.arange(12) xd_preds = xd.predict(days_since_launch_pred) . plt.figure(figsize=(25, 13)) plt.plot(days_since_launch_plus_future, xd_preds, label=&quot;exponential decay fit&quot;) plt.plot(days_since_launch, medium_post_views, label=&quot;actual&quot;) plt.legend(fontsize=fs/2) plt.title(&quot;Medium views decay&quot;, fontsize=fs) plt.ylabel(&quot;Views&quot;, fontsize=fs) plt.yticks(fontsize=fs) plt.xlabel(&quot;Days since launch&quot;, fontsize=fs) plt.xticks(fontsize=fs); . medium_post_views/medium_post_views.max() . array([1. , 0.45714286, 0.13771429, 0.07 , 0.05657143, 0.03314286]) . xd = ExponentialDecayRegressor(starting_values=None) xd.fit(days_since_launch, medium_post_views/medium_post_views.max()) days_since_launch_plus_future = np.arange(12) xd_preds = xd.predict(days_since_launch_pred) . plt.figure(figsize=(25, 13)) plt.plot(days_since_launch_plus_future, xd_preds, label=&quot;exponential decay fit&quot;) plt.plot(days_since_launch, medium_post_views/medium_post_views.max(), label=&quot;actual&quot;) plt.legend(fontsize=fs/2) plt.title(&quot;Medium views decay&quot;, fontsize=fs) plt.ylabel(&quot;Views&quot;, fontsize=fs) plt.yticks(fontsize=fs) plt.xlabel(&quot;Days since launch&quot;, fontsize=fs) plt.xticks(fontsize=fs); . from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier from sklearn.linear_model import LogisticRegression from sklearn import metrics from sklearn.model_selection import train_test_split from sklearn.datasets import load_breast_cancer, load_diabetes . rf = GradientBoostingClassifier(n_estimators=30, max_depth=4) . X, y = load_breast_cancer(return_X_y=True) train_ix, test_ix = train_test_split(np.arange(X.shape[0])) train_X, train_y = X[train_ix], y[train_ix] test_X, test_y = X[test_ix], y[test_ix] . from sklearn.base import BaseEstimator, ClassifierMixin from sklearn.ensemble import GradientBoostingClassifier from sklearn.linear_model import LogisticRegression from sklearn.preprocessing import OneHotEncoder class TreeEmbeddingLogisticRegression(BaseEstimator, ClassifierMixin): &quot;&quot;&quot;Fits a logistic regression model on tree embeddings. &quot;&quot;&quot; def __init__(self, **kwargs): self.kwargs = kwargs self.gbm = GradientBoostingClassifier(**kwargs) self.lr = LogisticRegression(penalty=&quot;l1&quot;, solver=&quot;liblinear&quot;) self.bin = OneHotEncoder() def fit(self, X, y=None): self.gbm.fit(X, y) X_emb = self.gbm.apply(X).reshape(X.shape[0], -1) X_emb = self.bin.fit_transform(X_emb) self.lr.fit(X_emb, y) def predict(self, X, y=None, with_tree=False): if with_tree: preds = self.gbm.predict(X) else: X_emb = self.gbm.apply(X).reshape(X.shape[0], -1) X_emb = self.bin.transform(X_emb) preds = self.lr.predict(X_emb) return preds def predict_proba(self, X, y=None, with_tree=False): if with_tree: preds = self.gbm.predict_proba(X) else: X_emb = self.gbm.apply(X).reshape(X.shape[0], -1) X_emb = self.bin.transform(X_emb) preds = self.lr.predict_proba(X_emb) return preds . lr_tree = TreeEmbeddingLogisticRegression(n_estimators=30, max_depth=4) . lr_tree.fit(train_X, train_y) . lr_tree_preds = lr_tree.predict(test_X) tree_preds = lr_tree.predict(test_X, with_tree=True) . metrics.roc_auc_score(test_y, lr_tree_preds) . 0.9444799658994033 .",
            "url": "https://conormm.github.io/blog/2021/04/11/lesser-known-data-scienec-techniques.html",
            "relUrl": "/2021/04/11/lesser-known-data-scienec-techniques.html",
            "date": " • Apr 11, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "How to optimize your webpage with simple Python code (code)",
            "content": "import numpy as np import matplotlib.pyplot as plt import seaborn as sns import pandas as pd from scipy.stats import beta n_trials = 10000 sns.set_style(&quot;whitegrid&quot;) get_ipython().run_line_magic(&#39;matplotlib&#39;, &#39;inline&#39;) from IPython.core.display import display, HTML display(HTML(&quot;&lt;style&gt;.container { width:80% !important; }&lt;/style&gt;&quot;)) . class Environment: &quot;&quot;&quot;Class for simulating an experiment in whichi multiple options are presented to users. For simulation purposes we set the expected payout to let the sampling algorithm find the optimal option across n_trials. &quot;&quot;&quot; def __init__(self, options, payouts, n_trials): self.options = options self.payouts = payouts self.n_trials = n_trials self.total_reward = 0 self.n_options = len(options) self.shape = (self.n_options, n_trials) def run(self, agent): &quot;&quot;&quot;Run the simulation with the agent. agent must be a class with choose_option and update methods.&quot;&quot;&quot; for i in range(self.n_trials): # agent makes a choice x_chosen = agent.choose_option() # Environment returns reward # In a real setting this wouldn&#39;t exist and the model # would be updated directly using the number of successes (presented and clickthrough event) # and failures (presented and no clickthrough event) reward = np.random.binomial(1, p=self.payouts[x_chosen]) # agent learns of reward agent.reward = reward # agent updates parameters based on the data agent.update() self.total_reward += reward agent.collect_data() return self.total_reward def plot_k_choices(agent, env): cmap = plt.get_cmap(&quot;tab10&quot;, env.n_options) x = np.arange(0, agent.n_trials) plt.figure(figsize=(30, 12)) plt.scatter(x, agent.option_i.round().astype(int)+1, cmap=cmap, c=agent.option_i.round().astype(int)+1, marker=&quot;.&quot;, alpha=1) plt.title(agent, fontsize=22, fontweight=&quot;bold&quot;) plt.xlabel(&quot;Trial&quot;, fontsize=22, fontweight=&quot;bold&quot;) plt.xticks(fontsize=15) plt.ylabel(&quot;Option&quot;, fontsize=22, fontweight=&quot;bold&quot;) plt.yticks(fontsize=15) plt.yticks(np.array(range(env.n_options))+1) plt.colorbar(); . class ThompsonSampler: &quot;&quot;&quot;Thompson Sampling using Beta distribution associated with each option. The beta distribution will be updated when rewards associated with each option are observed. &quot;&quot;&quot; def __init__(self, env, n_learning=0): # boilier plate data storage self.env = env self.n_learning = n_learning self.options = env.options self.n_trials = env.n_trials self.payouts = env.payouts self.option_i = np.zeros(env.n_trials) self.r_i = np.zeros(env.n_trials) self.thetas = np.zeros(self.n_trials) self.data = None self.reward = 0 self.total_reward = 0 self.option = 0 self.trial = 0 # parameters of beta distribution self.alpha = np.ones(env.n_options) self.beta = np.ones(env.n_options) # estimated payout rates self.theta = np.zeros(env.n_options) def collect_data(self): self.data = pd.DataFrame(dict(option=self.option_i, reward=self.r_i)) self.n_learning = n_learning def choose_option(self): # sample from posterior (this is the thompson sampling approach) # this leads to more exploration because machines with &gt; uncertainty can then be selected as the machine self.theta = np.random.beta(self.alpha, self.beta) # select machine with highest posterior p of payout if self.trial &lt; self.n_learning: self.option = np.random.choice(self.options) else: self.option = self.options[np.argmax(self.theta)] return self.option def update(self): #update dist (a, b) = (a, b) + (r, 1 - r) # a,b are the alpha, beta parameters of a Beta distribution self.alpha[self.option] += self.reward # i.e. only increment b when it&#39;s a swing and a miss. 1 - 0 = 1, 1 - 1 = 0 self.beta[self.option] += 1 - self.reward # store the option presented on each trial self.thetas[self.trial] = self.theta[self.option] self.option_i[self.trial] = self.option self.r_i[self.trial] = self.reward self.trial += 1 def collect_data(self): self.data = pd.DataFrame(dict(option=self.option_i, reward=self.r_i)) def __str__(self): return &quot;ThompsonSampler&quot; . options_and_payouts = { &quot;option-1&quot; : 0.07, &quot;option-2&quot; : 0.05, &quot;option-3&quot; : 0.04, &quot;option-4&quot; : 0.01 } . machines = [0, 1, 2, 3] payouts = [0.07, 0.05, 0.04, 0.01] labels = [&quot;V&quot; + str(i) + (str(p)) for i, p in zip(machines, payouts)] assert len(machines) == len(payouts) . en2 = Environment(machines, payouts, 1000) tsa = ThompsonSampler(env=en2) en2.run(agent=tsa) tsa.data.option.value_counts() . 0.0 823 2.0 74 3.0 52 1.0 51 Name: option, dtype: int64 . plt.figure(figsize=(14, 7)) plot_k_choices(tsa, en2); . &lt;Figure size 1008x504 with 0 Axes&gt; . x = np.arange(0, .2, 0.0001) cmap = list(plt.cm.tab10(list(range(len(machines))))) plt.figure(figsize=(40, 20)) # plot 1 n_rounds = 0 en = Environment(machines, payouts, n_rounds) tsa = ThompsonSampler(env=en) plt.subplot(231) for i in range(len(machines)): pdf = beta(tsa.alpha[i], tsa.beta[i]).pdf(x) c = cmap[i] plt.plot(x, pdf, c=c, label=i+1, alpha=.6) plt.title(f&quot;Prior distribution for each variant (uniform between 0 and 1)&quot;) plt.legend(); # plot 2 n_rounds = 500 en = Environment(machines, payouts, n_rounds) tsa = ThompsonSampler(env=en) en.run(agent=tsa) plt.subplot(232) for i in range(len(machines)): pdf = beta(tsa.alpha[i], tsa.beta[i]).pdf(x) c = cmap[i] plt.plot(x, pdf, c=c, label=i+1, alpha=.6) plt.title(f&quot;Probability distributions after {n_rounds}&quot;) plt.legend(); # plot 3 en = Environment(machines, payouts, n_rounds) tsa = ThompsonSampler(env=en) en.run(agent=tsa) n_rounds = 1000 plt.subplot(233) for i in range(len(machines)): pdf = beta(tsa.alpha[i], tsa.beta[i]).pdf(x) c = cmap[i] plt.plot(x, pdf, c=c, label=i+1, alpha=.6) plt.title(f&quot;Probability distributions after {n_rounds}&quot;) plt.legend(); .",
            "url": "https://conormm.github.io/blog/2021/04/10/thompson-samping.html",
            "relUrl": "/2021/04/10/thompson-samping.html",
            "date": " • Apr 10, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Why boosting works",
            "content": "Boosting . In this post I take a look at boosting with a focus on building an intution for why this technique works. Most people who work in data science and machine learning will know that gradient boosting is one of the most powerful and effective algorithms out there. It continues to be one of the most successful ML techniques in Kaggle comps and is widely used in practice across a variety of use cases. . To build an intuition for boosting, I&#39;ll build a simple booster using the Scikit learn Decision Tree implementation. It goes without saying that the go to technique for gradient boosting is the excellent XGboost package. This post should help to develop your understanding of why boosting is so effective in predictive modelling problems. . At a high-level boosting sits within the Ensemble family of ML algorithms. Boosting involves sequentially training weak learners - where a weak learner is a low bias estimator - to predict some outcome. The interesting thing is that each learner does not predict the original tartget. Instead, each learner attempts to predict the mistakes of the previous learner. In practice this means that learner-1 will attempt to predict the target outcome directly and learner-2 will attempt to predict the residual of learner-1. This process of predicting residuals continues through to the final learner. The final prediction can then be made by taking the sum of all the individual learners. This is an extremely effective means of predicting things, but the intuition for this isn&#39;t always immediately clear. I hope to make this intuition more accessible in this post. . Let&#39;s start by importing some dependencies . from sklearn.tree import DecisionTreeRegressor import matplotlib.pyplot as plt import seaborn as sns import pandas as pd import numpy as np sns.set_style(&quot;whitegrid&quot;) . Let&#39;s create some toy data: . n = 100 X = np.linspace(0, 10, n) y = X**2 + 10 - (20 * np.random.random(n)) X = X[:, np.newaxis] plt.figure(figsize=(15, 4)) plt.scatter(X, y, alpha=.7); . The functions below create a boosted regression learner using Decision Trees. Decision trees are one of the most popular and effective learners for ensembles (though technically you boost any algorithm). Decisions trees are a nice choice however because 1) they train quickly and 2) they can model non-linearities. . I have tried to keep the functions below super simple. many_trees returns a list of decision trees, boost fits the decision trees sequentially by first predicting the target outcome y with tree-0 then from tree-1-n predicts the residuals and predict iterates through the list of fitted decision trees and returns each trees prediction. plot_fits is a convienence functions that sums the prediction of n trees and returns the fitted line and the residuals. . Implementing boosting using Decision Trees . def many_trees(n_trees, clf=False, **kwargs): trees = [DecisionTreeRegressor(**kwargs) for i in range(n_trees)] return trees def boost(trees, X, y, clf=False): fitted = [] for tree in trees: tree.fit(X, y) yhat = tree.predict(X) y = (y-yhat) fitted.append(tree) return fitted def predict(trees, X): return np.array([tree.predict(X) for tree in trees]).T . With the boosting functonality implemented, we can now fit the trees. Given the simplicity of the predicton problem, I&#39;ll make the learners extremely week by setting the max-depth of each tree to 1. This limits each tree to one split of X when predicting y. . learners = many_trees(30, max_depth=1, clf=False) fitted = boost(learners, X, y, clf=False) boosted_yhat = predict(fitted, X) xfit = np.linspace(0, 10, 100).reshape(-1, 1) #dtfit = predict(learners, xfit) # predict over the range of X to def plot_fits(n_trees, row): preds_t = boosted_yhat[:, :n_trees] boosted_pred = preds_t.sum(1) res = boosted_pred-y axes[row, 0].plot(xfit, boosted_pred, c=&#39;red&#39;) axes[row, 0].scatter(X, y) axes[row, 0].set_title(f&quot;Fit after {n_trees} trees&quot;, fontsize=15) axes[row, 1].scatter(sample_ix, res, alpha=0.7) axes[row, 1].plot(res, color=&#39;r&#39;, alpha=0.7) axes[row, 1].set_title(f&quot;Residuals after {n_trees} trees&quot;, fontsize=15) . It&#39;s the residuals, silly! . Boosting works by fitting successive models to the residuals of the previous model. It is common to plot residuals as part of the model evaluation process. Typically you check residuals to ensure that they are randon and that there are not obvious patterns. If there are patterns in the residuals it is a sign that you are missing key information about the target variable and are underfitting the data. Essentially patterns in residuals represent information about the relationship between X and y that can be modelled. . Boosting takes advantage of this insight by fitting the residuals across the sequence of models. This is why we use weak learners - such as highly regaularised decision trees - in boosting, we want each single learner to underfit the data, thereby affording the next learner the opportunity to correct its mistakes (possibly with a different sample and feature space to the previous learner). . We can see this process play out in the plots below. Each plot shows the fitted line to the data from successive boosted trees. In panel 1 we show the first prediction and it is easy to see that this leaves a clear pattern in the residuals. In the next panel we show the fit after five boosted trees. The boosting has given the model more flexibility to fit the data, but it still leaves clear exploitable patterns in the data. In the next four panels we increase the number of boosted predictions and by the final panel you can see that the residuals begin to look quite random and the line appears to be a decent fit for the data. . fig, axes = plt.subplots(nrows=6, ncols=2, figsize=(20,25)) plot_fits(1, 0) plot_fits(5, 1) plot_fits(15, 2) plot_fits(20, 3) plot_fits(25, 4) plot_fits(30, 5) fig.tight_layout() . It&#39;s also informative to plot each fit across the data by adding each succesive set of predictions and plotting the line. . plt.figure(figsize=(15, 4)) pred = 0 for i in range(len(learners)): pred += boosted_yhat[:, i] plt.plot(xfit, pred) plt.plot(xfit, predict(learners, X).sum(1)) plt.xlabel(&quot;X&quot;) plt.ylabel(&quot;y&quot;); plt.scatter(X, y, alpha=.4) . &lt;matplotlib.collections.PathCollection at 0x1a3df7ec50&gt; . There is obviously a lot more to Boosting than described in this post, but I think it is useful to have an intuitive understanding for the core reason this technique works and hopefully this post has make this clear! One final thought is that when you use Boosting you need to carefully validate your model as this approach can easily overfit. For example, if we increase the max-depth of the trees to 4, we can observe that the model begins to fit individual data points rather than the general trend in the data. . learners = many_trees(30, max_depth=4, clf=False) fitted = boost(learners, X, y, clf=False) boosted_yhat = predict(fitted, X) plt.figure(figsize=(15, 4)) plt.scatter(X, y, alpha=.4) pred = 0 for i in range(len(learners)): pred += boosted_yhat[:, i] plt.plot(xfit, pred) plt.plot(xfit, predict(learners, X).sum(1)) plt.xlabel(&quot;X&quot;) plt.ylabel(&quot;y&quot;); sample_ix = np.arange(X.shape[0]) plt.figure(figsize=(15, 4)) plt.scatter(sample_ix, pred-y) plt.plot(pred-y, color=&#39;r&#39;, alpha=0.4) . [&lt;matplotlib.lines.Line2D at 0x1a3e46fa90&gt;] . Rather than creating a randomly distributed set of residuals the model has learned to perfectly predict y given X. This might look nice, but in effect the model has become a lookup table and hasn&#39;t learned the fundamental structure of the data. A good thing to do therefore when training boosting models is to plot the residuals - this will give you a clear steer on whether or not your model is overfitting. . Hope you found this useful! .",
            "url": "https://conormm.github.io/blog/2020/02/20/boosting-intuition.html",
            "relUrl": "/2020/02/20/boosting-intuition.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "R To Py Data Wrangling",
            "content": "R to python data wrangling snippets . The dplyr package in R makes data wrangling significantly easier. The beauty of dplyr is that, by design, the options available are limited. Specifically, a set of key verbs form the core of the package. Using these verbs you can solve a wide range of data problems effectively in a shorter timeframe. Whilse transitioning to Python I have greatly missed the ease with which I can think through and solve problems using dplyr in R. The purpose of this document is to demonstrate how to execute the key dplyr verbs when manipulating data using Python (with the pandas package). . dplyr is organised around six key verbs: . . filter : subset a dataframe according to condition(s) in a variable(s) | select : choose a specific variable or set of variables | arrange : order dataframe by index or variable | group_by : create a grouped dataframe | summarise : reduce variable to summary variable (e.g. mean) | mutate : transform dataframe by adding new variables | . . The excellent pandas package in Python easily allows you to implement all of these actions (and much, much more!). Below are some snippets to highlight some of the more basic conversions. . @Conormacd . June 8th 2018 update: All of this code still works in pandas and should ease the transition from R, but for those interested in getting the most out of the package I strongly recommend this series on modern pandas https://tomaugspurger.github.io/modern-1-intro.html . Filter . R . filter(df, var &gt; 20000 &amp; var &lt; 30000) filter(df, var == &#39;string&#39;) # df %&gt;% filter(var != &#39;string&#39;) df %&gt;% filter(var != &#39;string&#39;) df %&gt;% group_by(group) %&gt;% filter(sum(var) &gt; 2000000) . Python . df[(df[&#39;var&#39;] &gt; 20000) &amp; (df[&#39;var&#39;] &lt; 30000)] df[df[&#39;var&#39;] == &#39;string&#39;] df[df[&#39;var&#39;] != &#39;string&#39;] df.groupby(&#39;group&#39;).filter(lambda x: sum(x[&#39;var&#39;]) &gt; 2000000) . Select . R . select(df, var1, var2) select(df, -var3) . Python . df[[&#39;var1&#39;, &#39;var2&#39;]] df.drop(&#39;var3&#39;, 1) . Arrange . R . arrange(df, var1) arrange(df, desc(var1)) . Python . df.sort_values(&#39;var1&#39;) df.sort_values(&#39;var1&#39;, ascending=False) . Grouping . R . df %&gt;% group_by(group) df %&gt;% group_by(group1, group2) df %&gt;% ungroup() . Python . df.groupby(&#39;group1&#39;) df.groupby([&#39;group1&#39;, &#39;group2&#39;]) df.reset_index() / or when grouping: df.groupby(&#39;group1&#39;, as_index=False) . Summarise / Aggregate df by group . R . df %&gt;% group_by(group) %&gt;% summarise(mean_var1 = mean(var1)) df %&gt;% group_by(group1, group2) %&gt;% summarise(mean_var1 = mean(var1), sum_var1 = sum(var1), count_var1 = n()) df %&gt;% group_by(group1, group2) %&gt;% summarise(mean_var1 = mean(var1), sum_2 = sum(var2), var3 = first(var3)) . Python . df.groupby(&#39;group1&#39;)[&#39;var1&#39;].agg({&#39;mean_col&#39; : np.mean()}) # pass dict to specifiy column name df.groupby([&#39;group1&#39;, &#39;group2&#39;])[&#39;var1].agg([&#39;mean&#39;, &#39;sum&#39;, &#39;count&#39;]) # for count also consider &#39;size&#39;. size will return n for NaN values also, whereas &#39;count&#39; will not. # first perform the aggregation group_agg = df.groupby([&quot;group1&quot;, &quot;group2&quot;]).agg({ &quot;var1&quot; : [&quot;mean&quot;], &quot;var2&quot; : [&quot;sum&quot;], &quot;var3&quot; : [&quot;first&quot;] }) # second rename the columns by joining the column name with the agg function (e.g. &quot;var1_mean&quot;) group_agg.columns = [&quot;_&quot;.join(x) for x in group_agg.columns.ravel()] # You can also pass multiple functions to aggregate the same column e.g: group_agg = df.groupby([&quot;group1&quot;, &quot;group2&quot;]).agg({&quot;var1&quot; : [&quot;mean&quot;, &quot;std&quot;, &quot;sum&quot;]}) . Mutate / transform df by group . R . df %&gt;% group_by(group) %&gt;% mutate(mean_var1 = mean(var1)) . Python . df.groupby(&#39;group&#39;).assign(mean_var1 = lambda x: np.mean(x.var1) . Distinct . R . df %&gt;% distinct() df %&gt;% distinct(col1) # returns dataframe with unique values of col1 . Python . df.drop_duplicates() df.drop_duplicates(subset=&#39;col1&#39;) # returns dataframe with unique values of col1 . Sample . R . sample_n(df, 100) sample_frac(df, 0.5) . Python . df.sample(100) df.sample(frac=0.5) .",
            "url": "https://conormm.github.io/blog/2020/01/26/R-to-Py-data-wrangling.html",
            "relUrl": "/2020/01/26/R-to-Py-data-wrangling.html",
            "date": " • Jan 26, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "I’m a data scientist, currently working at Amazon in London. I don’t blog as frequently as I would like but I’m going to try to post short-form tutorials and other interesting data science pieces here. Feel free to look around, comment and enjoy! . Conor . This website is powered by fastpages [^1]. .",
          "url": "https://conormm.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://conormm.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}